{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f60b7439",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "962e3a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5550, 5)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[(data[\"No_of_Char\"]<350)]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5cc12d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean input text\n",
    "def clean_data(inputText):\n",
    "    text = re.sub('[^a-zA-Z]', ' ', inputText) #Replacing all non-alphabetic characters with a space\n",
    "    text = text.lower() #converting input to lowercase\n",
    "    text = text.split()\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d6025bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/14/0ss6gyz950z79_k9zp5x0bhm0000gn/T/ipykernel_18332/1539644974.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"cleaned_text\"] = data[\"input Text\"].apply(clean_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    go until jurong point crazy available only in ...\n",
       "1                              ok lar joking wif u oni\n",
       "2    free entry in a wkly comp to win fa cup final ...\n",
       "3          u dun say so early hor u c already then say\n",
       "4    nah i don t think he goes to usf he lives arou...\n",
       "Name: cleaned_text, dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning input text\n",
    "data[\"cleaned_text\"] = data[\"input Text\"].apply(clean_data)\n",
    "data[\"cleaned_text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c55cbf",
   "metadata": {},
   "source": [
    "**Here, I replaced all non-alphabetic characters with a space and converted the text to lower case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "55ef2c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/14/0ss6gyz950z79_k9zp5x0bhm0000gn/T/ipykernel_18332/2764974977.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"Tokenized_Text\"]=data.apply(lambda row: nltk.word_tokenize(row[\"cleaned_text\"]), axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [go, until, jurong, point, crazy, available, o...\n",
       "1                       [ok, lar, joking, wif, u, oni]\n",
       "2    [free, entry, in, a, wkly, comp, to, win, fa, ...\n",
       "3    [u, dun, say, so, early, hor, u, c, already, t...\n",
       "4    [nah, i, don, t, think, he, goes, to, usf, he,...\n",
       "Name: Tokenized_Text, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenization\n",
    "data[\"Tokenized_Text\"]=data.apply(lambda row: nltk.word_tokenize(row[\"cleaned_text\"]), axis=1)\n",
    "data[\"Tokenized_Text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7ba69c",
   "metadata": {},
   "source": [
    "**Here, I split the sentence into words(tokens) to remove stopwords in the next step.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "917aa8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to Remove stopwords\n",
    "def removing_stopwords(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_text = [word for word in text if word not in stop_words]\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ba881c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hashmithakatta/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a18f154a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/14/0ss6gyz950z79_k9zp5x0bhm0000gn/T/ipykernel_18332/2569495026.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"No_stopword_Text\"] = data[\"Tokenized_Text\"].apply(removing_stopwords)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [go, jurong, point, crazy, available, bugis, n...\n",
       "1                       [ok, lar, joking, wif, u, oni]\n",
       "2    [free, entry, wkly, comp, win, fa, cup, final,...\n",
       "3        [u, dun, say, early, hor, u, c, already, say]\n",
       "4       [nah, think, goes, usf, lives, around, though]\n",
       "Name: No_stopword_Text, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"No_stopword_Text\"] = data[\"Tokenized_Text\"].apply(removing_stopwords)\n",
    "data[\"No_stopword_Text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590c63dc",
   "metadata": {},
   "source": [
    "**Stopwords give meaning to the sentence structure but do not contribute in NLP. so, I removed stopwords from the input text.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
